### Spatial modelling and spatial interpolation

* Simple ways of interpolation
* Simple statistical models for interpolation
* Geostatistical interpolation
* Deterministic models
* Combined approaches

### Taking a step back
Why do we need models?
* to understand {\em relations} or {\em processes}
* to assess (predict, forcast, map) something we do 
or did not measure {\em and cannot see}
* to assess the consequence of decisions (scenarios)
where we cannot measure

### A sample data set
```{r}
library(sp)
data(meuse.riv)
data(meuse)
coordinates(meuse) = c("x", "y")
meuse.sr = SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
spplot(meuse, "zinc", col.regions=bpy.colors(),  main = "zinc, ppm",
       cuts = c(100,200,400,700,1200,2000), key.space = "right",
       sp.layout= list("sp.polygons", meuse.sr, fill = "lightblue")
)
```

### Thiessen "polygons", 1-NN
```{r}

library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y

meuse.th = idw(zinc~1, meuse, meuse.grid, nmax = 1)

spplot(meuse.th[1], 
	col.regions = bpy.colors(30), cuts = 29,
	sp.layout = list("sp.points", meuse, col = 3, cex=.5),
	main = "Zinc, 1-nearest neighbour")
```

### Zinc concentration vs. distance to river
```{r}
library(sp)
data(meuse)
plot(log(zinc)~sqrt(dist),meuse)
abline(lm(log(zinc)~sqrt(dist),meuse))
```

### Zinc conc. vs. distance to river: map of linear trend
```{r}
meuse.grid$sqrtdist = sqrt(meuse.grid$dist)
spplot(meuse.grid["sqrtdist"], col.regions = bpy.colors())
```

### Simple ways of interpolation: idw
\includegraphics[scale=0.5]{idw}
}

### Inverse distance weighted interpolation
Uses a {\color{red} weighted} average:
$$\hat{Z}(s_0) = \sum_{i=1}^n \lambda_i Z(s_i)$$
with $s_0 = \{x_0, y_0\}$,
or $s_0 = \{x_0, y_0, \mbox{depth}_0\}$
weights inverse proportional to power $p$ of distance:
$$\lambda_i = \frac{|s_i-s_0|^{-p}}{\sum_{i=1}^n |s_i-s_0|^{-p}}$$
* power $p$: tuning parameter
* if for some $i$, $|s_i-s_0| = 0$, then $\lambda_i = 1$ and other
weights become zero
* $\Rightarrow$ {\color{red} exact} interpolator

### Effect of power $p$
\includegraphics[scale=.5]{id}\\
inverse distance power: {\color{black} 2}, {\color{red} .5}, {\color{green} 10}
}

\frame{\frametitle{Simple statistical models for interpolation}
\includegraphics[scale=.5]{lm}
}

\frame{\frametitle{Time series versus spatial data}
Differences:
\begin{itemize}
\item spatial data live in 2 (or 3) dimensions
\item there's no past and future
\item there's no simple conditional independence (AR)
\end{itemize}
Correspondences
\begin{itemize}
\item nearby observations are more alike (auto-correlation)
\item we can form moving averages
\item coordinate reference systems are a bit like time zones and DST
\end{itemize}
}

\frame{\frametitle{What information do we have?}
\begin{itemize}
\item We have measurements $Z(x)$, with $x$ two-dimensional
(location on the map)
\item we have $x$ and $y$ \pause
\item we may have land use data \pause
\item we may have soil type or geological data \pause
\item we may have remote sensing imagery \pause
\item we may have all kinds of relevant information, related
to processes that cause (or result from) $Z(x)$ \pause
\item we have google maps \pause
\end{itemize}
\color{red}We don't want to ignore anything important\color{black}
}

\frame{\frametitle{Regression or correlation?}}
(Correlation between two different variables, no auto-correlation) 

Correspondences:
\begin{itemize}
\item both are in the "classic statistics" book, and may involve hypothesis testing
\item both deal with {\em two} continuous variables
\item both look at (first order) {\em linear} relations
\item when correlation is significant, the regression {\em slope} is significant
\end{itemize}
Differences:
\begin{itemize}
\item Regression distinguishes $y$ from $x$: $y$ depends on $x$, not reverse;
\item the line $y=ax+b$ is {\em not} equal to the line $x = cx + d$
\item Correlation is symmetric: $Cor(x,y)=Cor(y,c)$
\item Correlation coefficient is unitless and within $[-1,1]$, 
regression coeficients have data units
\item Regression is concerned with {\em prediction} of $y$ from $x$.
\end{itemize}

\frame{\frametitle{The power of regression models for spatial prediction}
... is hard to overestimate. Regression and correlation are the fork
and knife of statistics.
\begin{itemize}
\item linear models have endless application: polynomials, interactions, nested
effects, ANOVA/ANCOVA models, hypothesis testing, lack of fit testing, ...
\item predictors can be transformed non-linearly
\item linear models can be generalized: logistic regression, Poisson regression, ...,
to cope with discrete data (0/1 data, counts, log-normal)
\item many derived techniques solve one particular issue in regression, e.g.:
 \begin{itemize}
 \item ridge regression solves collinearity (extreme correlation among predictors)
 \item stepwise regression automatically selects "best" models among many candidates
 \item classification and regression trees
 \end{itemize}
\end{itemize}
}

\frame{\frametitle{Why is regression difficult in spatial problems?}
Regression models assume independent observations. Spatial data are always
to some degree spatially correlated. 
\pause
This does not mean we should discard regression, but rather think about
\begin{itemize}
\item to which extent is an outcome dependent on independence?
\item to which extent is regression {\em robust} agains a violated assumption 
of independent observations?
\item to which extent {\em is} the assumption violated? (how strong is the
correlation)
\end{itemize}
}

\frame{\frametitle{What is spatial correlation?}
Waldo Tobler's first law in geography:

Everything is related to everything else, but near things are more
related than distant things." [Tobler, 1970, p.236]

TOBLER, W. R. (1970). "A computer model simulation of urban growth in
the Detroit region". Economic Geography, 46(2): 234-240.

\pause \color{red}But how then is "being related" expressed?\color{black}
}
